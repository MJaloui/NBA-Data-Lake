# NBADataLake

![image](https://github.com/user-attachments/assets/da946492-8d8a-438e-8d3b-e3a00e43ad9f)




## **ğŸ”· Project Highlights ğŸ”·**

â›¹ğŸ¾â€â™€ï¸ This repository contains the setup_nba_data_lake.py script, which automates the creation of a data lake for NBA analytics using AWS 
    services. 

â›¹ğŸ¾â€â™€ï¸ The script integrates Amazon S3, AWS Glue, and Amazon Athena

â›¹ğŸ¾â€â™€ï¸ It also sets up the infrastructure needed to store and query NBA-related data.



## **ğŸ”§ Capabilities ğŸ”§**

**The setup_nba_data_lake.py script performs the following actions:**

ğŸ”¹ Creates an Amazon S3 bucket to store raw and processed data.

ğŸ”¹ Uploads sample NBA data (JSON format) to the S3 bucket.

ğŸ”¹ Creates an AWS Glue database and an external table for querying the data.

ğŸ”¹ Configures Amazon Athena for querying data stored in the S3 bucket.



## **ğŸš¨ Technologies ğŸš¨**

ğŸ”¹ **Cloud Provider**: AWS

ğŸ”¹ **Core Services**: S3, Glue, Athena

ğŸ”¹ **Command-Line Tool**: AWS CloudShell

ğŸ”¹ **Programming Language**: Python 3.x

ğŸ”¹ **Infrastructure as Code**: Python script for automating AWS resource creation

ğŸ”¹ **External API**: SportsData.io NBA API

ğŸ”¹ **Environment Management**: Environment variables for secure API key storage

ğŸ”¹ **IAM Security**: Least privilege policies for S3, Glue, and Athena

ğŸ”¹ **Data Querying**: Amazon Athena

ğŸ”¹ **Data Storage**: Amazon S3 (raw and processed data)

ğŸ”¹ **Data Cataloging**: AWS Glue



---



## **ğŸ‘€ Instructions ğŸ‘€**   

**ğŸ”¹ Prerequisites ğŸ”¹**

ğŸ”¹ Go to Sportsdata.io and create a free account

ğŸ”¹ IAM Role/Permissions: Ensure the user or role running the script has the following permissions:

ğŸ”¹ S3: s3:CreateBucket, s3:PutObject, s3:DeleteBucket, s3:ListBucket
  Glue: glue:CreateDatabase, glue:CreateTable, glue:DeleteDatabase, glue:DeleteTable
  Athena: athena:StartQueryExecution, athena:GetQueryResults


### **Steps:**   â¡ï¸â— [Click Here To View Detailed Visual Steps](https://github.com/MJaloui/NBADataLake/blob/main/VisualStepsHere.md) â—â¬…ï¸

1. Log into AWS and Open CloudShell Console

2. Create the setup_nba_data_lake.py file

3. In another window, go to [GitHub](https://github.com/MJaloui/NBADataLake) and copy the contents inside the setup_nba_data_lake.py file located in the SRC file to paste in the file
        you created in the cloudshell console.

4. Configure API key in the Python script.

5. Create .env file to create variables that store your API Key and NBA endpoint for your scripts.

6. Run the script

7. Manually Check For The Resources, validate the data is there.

8. Head over to Amazon Athena to try a query.

---

### **âœ”ï¸ Keynotes âœ”ï¸**

ğŸ”¹ Securing AWS services with least privilege IAM policies.

ğŸ”¹ Automating the creation of services with a script.

ğŸ”¹ Integrating external APIs into cloud-based workflows.


### **ğŸŒ± Opportunities for Growth ğŸŒ±**

ğŸ”¹ Automate data ingestion with AWS Lambda

ğŸ”¹ Implement a data transformation layer with AWS Glue ETL

ğŸ”¹ Add advanced analytics and visualizations (AWS QuickSight)

